{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e8ebac",
   "metadata": {},
   "source": [
    "<H1> CLTV Prediction with MLflow</H1>\n",
    "\n",
    "We are going to build simple machine learning models that predicts our customers lifetime value and compare their performances, now using MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd27577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e1fd9",
   "metadata": {},
   "source": [
    "<a name=1> <h1> 1. Feature Engineering </h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6169a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "import pickle\n",
    "\n",
    "with open(\"tx_cluster.pkl\", \"rb\") as f:\n",
    "    tx_cluster = pickle.load(f)\n",
    "\n",
    "tx_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical columns to numerical\n",
    "tx_class = pd.get_dummies(tx_cluster) #There is only one categorical variable segment\n",
    "tx_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50463353",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_class.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and show correlations\n",
    "corr_matrix = tx_class.corr()\n",
    "corr_matrix['LTVCluster'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ecb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and y, X will be feature set and y is the label - LTV\n",
    "X = tx_class.drop(['LTVCluster','m6_Revenue'],axis=1)\n",
    "y = tx_class['LTVCluster']\n",
    "\n",
    "#split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ff223",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Since our LTV Clusters are 3 types, high LTV, mid LTV and low LTV; we will perform multi class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"CLTV_testsize005\")\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d44c3",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "basemodelname = \"Logit_test\"\n",
    "with mlflow.start_run(run_name=basemodelname):\n",
    "    params = {\n",
    "        \"penalty\": None,\n",
    "        \"class_weight\": 'balanced'}\n",
    "    parsuf = '_'.join([key.replace('_','')+str(val).replace('.','') for key,val in params.items()])\n",
    "    modelname=f\"{basemodelname}_{parsuf}\"\n",
    "    mlflow.set_tag(\"model_name\", modelname)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    ltv_logreg = LogisticRegression(\n",
    "        penalty=params['penalty'],\n",
    "        class_weight=params['class_weight'],\n",
    "        max_iter=1000\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    acc_train = ltv_logreg.score(X_train, y_train)\n",
    "    acc_test = ltv_logreg.score(X_test[X_train.columns], y_test)\n",
    "\n",
    "    print(f\"Modelname: {modelname}\")\n",
    "    print('Accuracy of Logit classifier on training set: {:.2f}'.format(acc_train))\n",
    "    print('Accuracy of Logit classifier on test set: {:.2f}'.format(acc_test))\n",
    "\n",
    "    y_pred = ltv_logreg.predict(X_test)\n",
    "    # clfreport = classification_report(y_test, y_pred)\n",
    "    # print(clfreport)\n",
    "    test_prf1s = precision_recall_fscore_support(y_test, y_pred)\n",
    "    # print(f\"precision:{prf1s[0]}\\nrecall:{prf1s[1]}\\nf1-score:{prf1s[2]}\\naccuracy:{acc}\")\n",
    "\n",
    "    # log the skill metrics\n",
    "    mlflow.log_metric('train_acc', acc_train)\n",
    "    mlflow.log_metric('test_acc', acc_test)\n",
    "    mlflow.log_metric('test_macroavg_f1', np.mean(test_prf1s[2]))\n",
    "\n",
    "    # log the model as an artifact to enable later use\n",
    "    mlflow.sklearn.log_model(ltv_logreg, \"ltv_logreg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53828e9d",
   "metadata": {},
   "source": [
    "### 2. XGBoost: testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee93e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "basemodelname = \"xgboost_test\"\n",
    "with mlflow.start_run(run_name=basemodelname):\n",
    "    params = {\n",
    "        \"max_depth\": 4,\n",
    "        \"learning_rate\":0.05}\n",
    "    parsuf = '_'.join([key.replace('_','')+str(val).replace('.','') for key,val in params.items()])\n",
    "    modelname=f\"{basemodelname}_{parsuf}\"\n",
    "    mlflow.set_tag(\"model_name\", modelname)\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    ltv_xgb = xgb.XGBClassifier(\n",
    "        max_depth=params['max_depth'], \n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_jobs=-1\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    acc_train = ltv_xgb.score(X_train, y_train)\n",
    "    acc_test = ltv_xgb.score(X_test[X_train.columns], y_test)\n",
    "    \n",
    "    print(f\"Modelname: {modelname}\")\n",
    "    print('Accuracy of XGB classifier on training set: {:.2f}'.format(acc_train))\n",
    "    print('Accuracy of XGB classifier on test set: {:.2f}'.format(acc_test))\n",
    "    \n",
    "    y_pred = ltv_xgb.predict(X_test)\n",
    "    # clfreport = classification_report(y_test, y_pred)\n",
    "    # print(clfreport)\n",
    "    test_prf1s = precision_recall_fscore_support(y_test, y_pred)\n",
    "    # print(f\"precision:{prf1s[0]}\\nrecall:{prf1s[1]}\\nf1-score:{prf1s[2]}\\naccuracy:{acc}\")\n",
    "    \n",
    "    # log the skill metrics\n",
    "    mlflow.log_metric('train_acc', acc_train)\n",
    "    mlflow.log_metric('test_acc', acc_test)\n",
    "    mlflow.log_metric('test_macroavg_f1', np.mean(test_prf1s[2]))\n",
    "    \n",
    "    # log the model as an artifact to enable later use\n",
    "    mlflow.xgboost.log_model(ltv_xgb, \"ltv_xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd2df9",
   "metadata": {},
   "source": [
    "### 2b. XGboost: parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodelname = \"xgboost_paropt\"\n",
    "with mlflow.start_run(run_name=basemodelname):\n",
    "    params_list = {\n",
    "        \"max_depth\": [4, 5],\n",
    "        \"learning_rate\":[0.05, 0.1]}\n",
    "    \n",
    "    run_i = 0\n",
    "    for max_depth in params_list['max_depth']:\n",
    "        for learning_rate in params_list['learning_rate']:\n",
    "            run_i += 1\n",
    "            params = {\n",
    "                \"max_depth\": max_depth,\n",
    "                \"learning_rate\": learning_rate}\n",
    "            parsuf = '_'.join([key.replace('_','')+str(val).replace('.','') for key,val in params.items()])\n",
    "                \n",
    "            with mlflow.start_run(run_name=parsuf, nested=True) as subrun_i:\n",
    "                    \n",
    "                modelname=f\"{basemodelname}_{parsuf}\"\n",
    "                mlflow.set_tag(\"model_name\", modelname)\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "                ltv_xgb = xgb.XGBClassifier(\n",
    "                    max_depth=params['max_depth'], \n",
    "                    learning_rate=params['learning_rate'],\n",
    "                    n_jobs=-1\n",
    "                ).fit(X_train, y_train)\n",
    "\n",
    "                acc_train = ltv_xgb.score(X_train, y_train)\n",
    "                acc_test = ltv_xgb.score(X_test[X_train.columns], y_test)\n",
    "\n",
    "                print(f\"Modelname: {modelname}\")\n",
    "                print('Accuracy of XGB classifier on training set: {:.2f}'.format(acc_train))\n",
    "                print('Accuracy of XGB classifier on test set: {:.2f}'.format(acc_test))\n",
    "\n",
    "                y_pred = ltv_xgb.predict(X_test)\n",
    "                # clfreport = classification_report(y_test, y_pred)\n",
    "                # print(clfreport)\n",
    "                test_prf1s = precision_recall_fscore_support(y_test, y_pred)\n",
    "                # print(f\"precision:{prf1s[0]}\\nrecall:{prf1s[1]}\\nf1-score:{prf1s[2]}\\naccuracy:{acc}\")\n",
    "\n",
    "                # log the skill metrics\n",
    "                mlflow.log_metric('train_acc', acc_train)\n",
    "                mlflow.log_metric('test_acc', acc_test)\n",
    "                mlflow.log_metric('test_macroavg_f1', np.mean(test_prf1s[2]))\n",
    "\n",
    "                # log the model as an artifact to enable later use\n",
    "                mlflow.xgboost.log_model(ltv_xgb, \"ltv_xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a0627",
   "metadata": {},
   "source": [
    "## Test split: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlflow.set_experiment(\"CLTV_testsize02\")\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "basemodelname = \"TestSplit02_Logit_test\"\n",
    "with mlflow.start_run(run_name=basemodelname):\n",
    "    params = {\n",
    "        \"penalty\": None,\n",
    "        \"class_weight\": 'balanced'}\n",
    "    parsuf = '_'.join([key.replace('_','')+str(val).replace('.','') for key,val in params.items()])\n",
    "    modelname=f\"{basemodelname}_{parsuf}\"\n",
    "    mlflow.set_tag(\"model_name\", modelname)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    ltv_logit = LogisticRegression(\n",
    "        penalty=params['penalty'],\n",
    "        class_weight=params['class_weight'],\n",
    "        max_iter=1000\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    acc_train = ltv_logit.score(X_train, y_train)\n",
    "    acc_test = ltv_logit.score(X_test[X_train.columns], y_test)\n",
    "\n",
    "    print(f\"Modelname: {modelname}\")\n",
    "    print('Accuracy of Logit classifier on training set: {:.2f}'.format(acc_train))\n",
    "    print('Accuracy of Logit classifier on test set: {:.2f}'.format(acc_test))\n",
    "\n",
    "    y_pred = ltv_logreg.predict(X_test)\n",
    "    # clfreport = classification_report(y_test, y_pred)\n",
    "    # print(clfreport)\n",
    "    test_prf1s = precision_recall_fscore_support(y_test, y_pred)\n",
    "    # print(f\"precision:{prf1s[0]}\\nrecall:{prf1s[1]}\\nf1-score:{prf1s[2]}\\naccuracy:{acc}\")\n",
    "\n",
    "    # log the skill metrics\n",
    "    mlflow.log_metric('train_acc', acc_train)\n",
    "    mlflow.log_metric('test_acc', acc_test)\n",
    "    mlflow.log_metric('test_macroavg_f1', np.mean(test_prf1s[2]))\n",
    "\n",
    "    # log the model as an artifact to enable later use\n",
    "    mlflow.sklearn.log_model(ltv_logit, \"ltv_logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5969d3be",
   "metadata": {},
   "source": [
    "## Use a model that we saved earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import xgboost\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    with open(\"tx_class.pkl\", \"rb\") as f:\n",
    "        tx_cluster = pickle.load(f)\n",
    "\n",
    "    #convert categorical columns to numerical\n",
    "    tx_class = pd.get_dummies(tx_cluster) #There is only one categorical variable segment\n",
    "    tx_class.head()\n",
    "\n",
    "    #create X and y, X will be feature set and y is the label - LTV\n",
    "    X = tx_class.drop(['LTVCluster','m6_Revenue'],axis=1)\n",
    "    y = tx_class['LTVCluster']\n",
    "\n",
    "    #split training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "    ltv_xgb = mlflow.xgboost.load_model(\"runs:/f9f153aa679d4a8697cf1b23a0d479ac/ltv_xgb\")\n",
    "\n",
    "    acc_train = ltv_xgb.score(X_train, y_train)\n",
    "    acc_test = ltv_xgb.score(X_test[X_train.columns], y_test)\n",
    "\n",
    "    print('Accuracy of XGB classifier on training set: {:.2f}'.format(acc_train))\n",
    "    print('Accuracy of XGB classifier on test set: {:.2f}'.format(acc_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
