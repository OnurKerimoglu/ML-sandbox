{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81792ce6",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/OnurKerimoglu/ML-sandbox/blob/main/Classification_Models_Evaluation.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae57070",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation of Classification Models\n",
    "\n",
    "Disclaimer: Material here is mostly based on the book by Aurelien Geron (2019) Hands-on ML 2nd Ed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b005f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Library Imports,  Basic Setup, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04421967",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"  # Scikit-Learn ≥0.20 is required\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", 'classification')\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee53b84",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST dataset: if not previously downloaded and pickled, download and pickle, otherwise just load from pickle\n",
    "import os, pickle\n",
    "mnist_fname = 'mnist_874.pkl'\n",
    "if os.path.exists(mnist_fname):\n",
    "    with open(mnist_fname, 'rb') as handle:\n",
    "        mnist = pickle.load(handle)\n",
    "else:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    with open(mnist_fname, 'wb') as handle:\n",
    "        pickle.dump(mnist, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c87434",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# the dataset is a dictionary, consisting of following fields:\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cc9f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape  # 70000 members of size 784 (28x28) pixels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d87bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# One example member\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "save_fig(\"some_digit_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09516481",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Label:\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019378ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the strings to integers\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0b2dd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# A function to plot some members side by side\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    # This is equivalent to n_rows = ceil(len(instances) / images_per_row):\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "\n",
    "    # Append empty images to fill the end of the grid, if needed:\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    padded_instances = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=0)\n",
    "\n",
    "    # Reshape the array so it's organized as a grid containing 28×28 images:\n",
    "    image_grid = padded_instances.reshape((n_rows, images_per_row, size, size))\n",
    "\n",
    "    # Combine axes 0 and 2 (vertical image grid axis, and vertical image axis),\n",
    "    # and axes 1 and 3 (horizontal axes). We first need to move the axes that we\n",
    "    # want to combine next to each other, using transpose(), and only then we\n",
    "    # can reshape:\n",
    "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * size,\n",
    "                                                         images_per_row * size)\n",
    "    # Now that we have a big image, we just need to show it:\n",
    "    plt.imshow(big_image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7225e39",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot 100 example members\n",
    "plt.figure(figsize=(9,9))\n",
    "example_images = X[:100]\n",
    "plot_digits(example_images, images_per_row=10)\n",
    "save_fig(\"more_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df5ef9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Do the train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226daa96",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Train-Test split (60:10)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a976a23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training a Binary Clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff493d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's simplify the problem, and build a model that identifies 5's only.\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea52265",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's pick a model and train it. Such as the Stochastic Gradient Descent (SGD) Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d57d3a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's browse some indecises and see how the predictions look like \n",
    "i = 0\n",
    "print(f'y[i] = {y[i]}, prediction (is this a 5)? {sgd_clf.predict([X[i]])[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae6ae7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04372430",
   "metadata": {},
   "source": [
    "Let's use cross_val_score() to evaluate the model using K-fold cross validation with 3 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e555f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a436e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Above 95 accuracy! Isn't this Amazing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb21e01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before deciding we are done, let's try a dumb classifier that just returns False no matter what:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad9cc2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91081d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As before, let's use cross_val_score() to evaluate the model using K-fold cross validation with 3 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d4cd0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2331a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Over 90% accuracy. But thinking about it, this was to be expected, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff522c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd5ec7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's obtain predictions for the entire train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01d0d7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c7be4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generate the confusion matrix for these predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a1405",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm  = confusion_matrix(y_train_5, y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc516e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here a nicer display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9828cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    " \n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "color = 'white'\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['Negative','Positive'])\n",
    "disp.plot(ax=ax, xticks_rotation='vertical')\n",
    "save_fig(\"confusion_matrix\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b796d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precison and Recall, and the Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c01ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "prec = precision_score(y_train_5, y_train_pred)\n",
    "rec = recall_score(y_train_5, y_train_pred)\n",
    "f1s = f1_score(y_train_5, y_train_pred)\n",
    "\n",
    "print (f'Precision: {prec}; Recall: {rec}; F1-Score: {f1s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3d2a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Visualising the dependency and choosing a threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443814d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# use the cross_val_predict() to get the scores of all instances \n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "\n",
    "# use precision_recall_curve() to compute precision and recall for all thresholds\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca588cae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A function to plot precision and recall vs thresholds\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                              \n",
    "    plt.axis([-50000, 50000, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d9935",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "save_fig(\"precision_recall_vs_threshold_plot\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc57e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we want a model that has at least 90% precision. What would be the corresponding recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bf9ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))                                                                  # Not shown\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "\n",
    "recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 # Not shown\n",
    "plt.plot([-50000, threshold_90_precision], [0.9, 0.9], \"r:\")                                # Not shown\n",
    "plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")# Not shown\n",
    "plt.plot([threshold_90_precision], [0.9], \"ro\")                                             # Not shown\n",
    "plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                             # Not shown\n",
    "save_fig(\"precision_recall_vs_threshold_plot_90precisionHL\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2074fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also plot the recall vs precision directly to analyze the relationship, and find a sweet spot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44075af",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A function to plot recall vs precision\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)\n",
    "\n",
    "# Produce the plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "save_fig(\"precision_vs_recall_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aabe72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we are aiming for 90% precision. Mark this on the curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4926f4e",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Produce the plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "\n",
    "# Mark the 90% precision\n",
    "plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "save_fig(\"precision_vs_recall_plot_90precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd5ed1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0ce7c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The Receiver Operating Characacteristic (ROC) curve plots the TPR against FPR, hence showing the trade-off between the two. \n",
    "- The diagonal represents a random classifier, and a good classifier stays as far away from the line. \n",
    "- Therefore the area under the curve indicates the skill of the model. AUC = 1 : perfect model; AUC = 0.5 : random model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33176b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the roc_curve() to compute the TPR and FPR for various threshold values\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "# Use the roc_auc_score() to compute area under the curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46862a42",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A function to plot fpr against tpr\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel('False Positive Rate (Fall-Out) (1 - Specificity)', fontsize=16) \n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49dd1c4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Make the plot\n",
    "plt.figure(figsize=(8, 6))                                    \n",
    "plot_roc_curve(fpr, tpr, label=f'SGD: {auc:.2f}')\n",
    "save_fig(\"roc_curve_plot\")                                   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d72f5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Comparing Models Using ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c9ed9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's train a Random Forest Classifier Model for the same data set and compare it against the SGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c6a4a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
    "                                    method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f946ad9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)\n",
    "\n",
    "auc_rf = roc_auc_score(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea35a7",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=f'SGD: {auc:.3f}')\n",
    "plot_roc_curve(fpr_forest, tpr_forest, f'RF: {auc_rf:.3f}')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=16)\n",
    "save_fig(\"roc_curve_comparison_plot\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "66px",
    "width": "280px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "366.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
